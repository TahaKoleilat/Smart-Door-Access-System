# -*- coding: utf-8 -*-
"""FYP Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kTJuERY8vPhPZgnPSlZjZ0U_xA8_i5_B
"""

!pip install opendatasets

import pandas as pd
import numpy as np
import os

import matplotlib.pyplot as plt
import seaborn as sns

import opendatasets as od

from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Conv2D,Dense, MaxPooling2D,Flatten,Dropout,Activation, BatchNormalization
from tensorflow.keras.optimizers import Adam,RMSprop,SGD
from keras import regularizers
import tensorflow as tf
from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau
import datetime
from tensorflow.keras.utils import plot_model

od.download("https://www.kaggle.com/datasets/sumansid/facemask-dataset",data_dir="dataset1")

od.download("https://www.kaggle.com/datasets/ahemateja19bec1025/facemask-dataset",data_dir="dataset2")

od.download("https://www.kaggle.com/datasets/vinaykudari/facemask",data_dir="dataset3")

od.download("https://www.kaggle.com/datasets/pranavsingaraju/facemask-detection-dataset-20000-images",data_dir="dataset4")

od.download("https://www.kaggle.com/datasets/ashiqurrahmantanzil/facemask-dataset",data_dir="dataset5")

train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,
                                   validation_split = 0.2, rotation_range=2,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        fill_mode='nearest')

valid_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,validation_split=0.2)

train_dataset1  = train_datagen.flow_from_directory(directory = '/content/dataset1/facemask-dataset',
                                                   class_mode = 'binary',
                                                   color_mode="rgb",
                                                    subset="training",
                                                     target_size = (128,128),
                                                   classes={'Mask': 0,'No Mask': 1})
valid_dataset1 = valid_datagen.flow_from_directory(directory = '/content/dataset1/facemask-dataset',
                                                  class_mode = 'binary',
                                                  subset = 'validation',
                                                  color_mode="rgb",
                                                    target_size = (128,128),
                                                  classes={'Mask': 0,'No Mask': 1})

train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,
                                   validation_split = 0.2, rotation_range=2,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        fill_mode='nearest')
valid_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,validation_split=0.2)
train_dataset2  = train_datagen.flow_from_directory(directory = '/content/dataset2/facemask-dataset/dataset/dataset',
                                                   class_mode = 'binary',
                                                   color_mode="rgb",
                                                    subset="training",
                                                     target_size = (128,128),
                                                   classes={'1': 0,'0': 1})
valid_dataset2 = valid_datagen.flow_from_directory(directory = '/content/dataset2/facemask-dataset/dataset/dataset',
                                                  class_mode = 'binary',
                                                  subset = 'validation',
                                                  color_mode="rgb",
                                                    target_size = (128,128),
                                                  classes={'1': 0,'0': 1})

train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,
                                   validation_split = 0.2, rotation_range=2,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        fill_mode='nearest')
valid_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,validation_split=0.2)
train_dataset3  = train_datagen.flow_from_directory(directory = '/content/dataset3/facemask/train',
                                                   class_mode = 'binary',
                                                   color_mode="rgb",
                                                    subset="training",
                                                     target_size = (128,128),
                                                   classes={'with_mask': 0,'without_mask': 1})
valid_dataset3 = valid_datagen.flow_from_directory(directory = '/content/dataset3/facemask/train',
                                                  class_mode = 'binary',
                                                  subset = 'validation',
                                                  color_mode="rgb",
                                                    target_size = (128,128),
                                                  classes={'with_mask': 0,'without_mask': 1})

train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,
                                   validation_split = 0.2, rotation_range=2,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        fill_mode='nearest')
valid_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,validation_split=0.2)
train_dataset4  = train_datagen.flow_from_directory(directory = '/content/dataset4/facemask-detection-dataset-20000-images',
                                                   class_mode = 'binary',
                                                   color_mode="rgb",
                                                    subset="training",
                                                     target_size = (128,128),
                                                   classes={'new_with_mask': 0,'new_without_mask': 1})
valid_dataset4 = valid_datagen.flow_from_directory(directory = '/content/dataset4/facemask-detection-dataset-20000-images',
                                                  class_mode = 'binary',
                                                  subset = 'validation',
                                                  color_mode="rgb",
                                                    target_size = (128,128),
                                                  classes={'new_with_mask': 0,'new_without_mask': 1})

train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,
                                   validation_split = 0.2, rotation_range=2,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        fill_mode='nearest')
valid_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,validation_split=0.2)
train_dataset5  = train_datagen.flow_from_directory(directory = '/content/dataset5/facemask-dataset/dataset_final',
                                                   class_mode = 'binary',
                                                   color_mode="rgb",
                                                    subset="training",
                                                     target_size = (128,128),
                                                   classes={'with_mask': 0,'without_mask': 1})
test_dataset = valid_datagen.flow_from_directory(directory = '/content/dataset5/facemask-dataset/dataset_final',
                                                  class_mode = 'binary',
                                                  subset = 'validation',
                                                  color_mode="rgb",
                                                    target_size = (128,128),
                                                 shuffle = False,
                                                  classes={'with_mask': 0,'without_mask': 1})

def combine_gen(*gens):
    while True:
        for g in gens:
            yield next(g)

training_set = combine_gen(train_dataset1,train_dataset2,train_dataset3,train_dataset4,train_dataset5)
valid_set =  combine_gen(valid_dataset1,valid_dataset2,valid_dataset3,valid_dataset4)
test_set = test_dataset

import numpy as np 
import pandas as pd


import seaborn as sn
from tensorflow import keras
from sklearn.metrics import confusion_matrix, classification_report
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

def build_model(resnet, nodes, drop_rate, activation):
    return Sequential([
        resnet,
        Flatten(),
        Dense(nodes,kernel_initializer='he_uniform'),
        BatchNormalization(),
        Activation('relu'),
        Dropout(drop_rate),
        Dense(1,activation='sigmoid')
    ])
def train_model(model, epochs, learning_rate):
   checkpoint_filepath = '/tmp/checkpointNew'
   earlyStopping = tf.keras.callbacks.EarlyStopping(
        patience=5,
        monitor="val_accuracy",
        verbose=1,)
   model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
       filepath=checkpoint_filepath,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True,
    save_freq="epoch")
   lrd = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss',patience = 3,verbose = 1,factor = 0.50, min_lr = 1e-10)
   adam = keras.optimizers.Adam(learning_rate=learning_rate)
   METRICS = [
      tf.keras.metrics.BinaryAccuracy(name='accuracy'),
      tf.keras.metrics.Precision(name='precision'),
      tf.keras.metrics.Recall(name='recall'),  
      tf.keras.metrics.AUC(name='auc'),
]
   model.compile(optimizer=adam, loss='binary_crossentropy', metrics=METRICS)
   history = model.fit(training_set, validation_data = valid_set,validation_steps = 100, batch_size = 512, steps_per_epoch= 200,  epochs = epochs,
                        callbacks=[model_checkpoint_callback,earlyStopping,lrd])
   return history
def plot_metrics(model, history, test):
    print("Accuracy of model on testing data : " , model.evaluate(test_set)[1]*100 , "%")
    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))
    fig.suptitle(" Metrics evaluation of the model ")

    ax1.plot(range(1, len(history.history['accuracy']) + 1), history.history['accuracy'])
    ax1.plot(range(1, len(history.history['val_accuracy']) + 1), history.history['val_accuracy'])
    ax1.set_title('History of Accuracy')
    ax1.set_xlabel('Epochs')
    ax1.set_ylabel('Accuracy')
    ax1.legend(['training', 'validation'])


    ax2.plot(range(1, len(history.history['loss']) + 1), history.history['loss'])
    ax2.plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'])
    ax2.set_title('History of Loss')
    ax2.set_xlabel('Epochs')
    ax2.set_ylabel('Loss')
    ax2.legend(['training', 'validation'])
    
    ax3.plot(range(1, len(history.history['auc']) + 1), history.history['auc'])
    ax3.plot(range(1, len(history.history['val_auc']) + 1), history.history['val_auc'])
    ax3.set_title('History of AUC')
    ax3.set_xlabel('Epochs')
    ax3.set_ylabel('AUC')
    ax3.legend(['training', 'validation'])
    
    ax4.plot(range(1, len(history.history['precision']) + 1), history.history['precision'])
    ax4.plot(range(1, len(history.history['val_precision']) + 1), history.history['val_precision'])
    ax4.set_title('History of Precision')
    ax4.set_xlabel('Epochs')
    ax4.set_ylabel('Precision')
    ax4.legend(['training', 'validation'])

    ax5.plot(range(1, len(history.history['recall']) + 1), history.history['recall'])
    ax5.plot(range(1, len(history.history['val_recall']) + 1), history.history['val_recall'])
    ax5.set_title('History of Recall')
    ax5.set_xlabel('Epochs')
    ax5.set_ylabel('Recall')
    ax5.legend(['training', 'validation'])
    plt.show()
def test_model(model, test_set):
    y_pred = model.predict(test_set)
    y_result = []
    for p in y_pred:
        y_result.append(int(p >= 0.5))
    
    y_actual = []
    for i in range(len(test_set)):
        for p in test_set[i][1]:
            y_actual.append(int(p >= 0.5))
    
    print(classification_report(y_actual, y_result))
    
    cm = tf.math.confusion_matrix(labels = y_actual, predictions = y_result)

    plt.figure(figsize = (10, 8))
    sn.heatmap(cm, annot = True, fmt = 'd')
    plt.xlabel('Predicted')
    plt.ylabel('Truth')
def CNN(resnet, dense_nodes, drop, activation, epochs, lr):
    model = build_model(resnet50, dense_nodes, drop, activation)
    model.summary()
    
    history = train_model(model, epochs, lr)
    
    plot_metrics(model, history, test_set)
    
    test_model(model, test_set)
    return model

resnet50 = tf.keras.applications.resnet.ResNet50(include_top = False, input_shape = (128, 128, 3), weights = 'imagenet', pooling = "Max")
for layer in resnet50.layers:
    layer.trainable=True
nodes = 256
drop_rate = 0.4
activation = 'sigmoid'
epochs = 10
lr = 0.0001

model = CNN(resnet50, nodes, drop_rate, activation, epochs, lr)

from keras.models import load_model

model.save('model_weights.h5')

model_json = model.to_json()
with open("model.json","w") as json_file:
    json_file.write(model_json)